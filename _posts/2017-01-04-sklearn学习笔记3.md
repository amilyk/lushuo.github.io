---
layout: post
title: "sklearn学习笔记（3）"
date: 2017-01-04 
description: "sklearn学习笔记"
tag: Scikit-learn

---

<h2> 过拟合</h2>  
<h3>过拟合定义</h3>  
简单的讲就是对训练集的数据能够非常好地拟合，一旦将该模型拟合测试集的时候效果就会非常差，这就是过拟合。   
标准定义：给定一个假设空间H，一个假设h属于H，如果存在其他的假设h’属于H,使得在训练样例上h的错误率比h’小，但在整个实例分布上h’比h的错误率小，那么就说假设h过度拟合训练数据。 ----《Machine Learning》Tom M.Mitchell  
想象某种学习算法产生了一个过拟合的分类器，这个分类器能够百分之百的正确分类样本数据（即再拿样本中的文档来给它，它绝对不会分错），但也就为了能够对样本完全正确的分类，使得它的构造如此精细复杂，规则如此严格，以至于任何与样本数据稍有不同的文档它全都认为不属于这个类别。  
<h3>过拟合演示</h3>  
这里采用的数据同样是sklearn中datasets中的数据，这次不用iris了，老用这个人家会烦的。。。好吧，换一个那就是你了，没错就是你，digits！！有没有被宠幸的赶脚哈  
模型嘛，还是SVM吧，嗯就这样。。  

工欲善其事必先利其器，啥也不说，先掉包zzZ  

```python
from sklearn.learning_curve import learning_curve
from sklearn.datasets import load_digits
from sklearn.svm import SVC
import matplotlib.pyplot as plt
import numpy as np
```

使用**learning_curve**的好处是我想看不同数据量大小时训练的状态，就是这么矫情<(￣3￣)> !  
来吧，导入数据，走起  

```python
digits=load_digits()
X=digits.data
y=digits.target
```

好了，是时候展示一波真正的技术了，先看一下SVC的参数gamma=0.001的时候图像如何，来波代码  

```python
train_sizes,train_loss,test_loss=learning_curve(SVC(gamma=0.001),X,y,cv=10,scoring='mean_squared_error', train_sizes=[0.1,0.25,0.5,0.75,1])
```

此时，train_sizes是自己定义的状态点，返回的train_loss和test_loss是10*5的矩阵，也就是说按列求平均数就可以求出每一个状态点的平均loss。  

```python
train_loss_mean=-np.mean(train_loss,axis=1)
test_loss_mean=-np.mean(test_loss,axis=1)
plt.plot(train_sizes,train_loss_mean,'o-',color='r',label='Training')
plt.plot(train_sizes,test_loss_mean,'o-',color='g',label='Testing')
```

绘制出来的图如下：

![](/images/sklearn/figure_3_2.png)

可以看出随着训练量的增大，训练集的误差在减少，测试集的误差也在减少，这说明这是一个很好的模型。  
现在，我把SVC的参数gamma=0.01，看看效果如何  

```python
train_sizes,train_loss,test_loss=learning_curve(SVC(gamma=0.01),X,y,cv=10,scoring='mean_squared_error',train_sizes=[0.1,0.25,0.5,0.75,1])
```

绘制图：  

![](/images/sklearn/figure_3_1.png)

这次可以清晰的看出随着我的训练数量不断增大，训练集的误差几乎为0，完美拟合训练集数据，但是在测试集中就会发现刚开始还挺好，之后出现回升，误差变大，这就是过拟合的现象。  
也就是说，过拟合主要原因是在模型复杂度越来越高的时候，对现有的训练集的数据更加能够拟合，但是由于模型复杂度高，规则较多，对未知的测试集就可能出现因为一点不符合规则就会被误判的情况。  
**改变gamma数值观察训练集和测试集误差：**  

```python
from sklearn.learning_curve import validation_curve
```

这就需要导入另外一个模块**validation_curve**，这个函数可以让我们修改模型内部的参数，很是方便！！  

```python
param_range=np.logspace(-6,-2.3,5)
train_loss,test_loss=validation_curve(SVC(),X,y,param_name='gamma',param_range=param_range,cv=10,scoring='mean_squared_error')
```

这里我把SVC中参数gamma的值设定在log值 -6到-2.3之间取值五个，分别画出它们的误差。  

```python
train_loss_mean=-np.mean(train_loss,axis=1)
test_loss_mean=-np.mean(test_loss,axis=1)
plt.plot(param_range,train_loss_mean,'o-',color='r',label='Training')
plt.plot(param_range,test_loss_mean,'o-',color='g',label='Testing')
plt.xlabel("gamma")
plt.ylabel("Loss")
plt.legend(loc='best')
```

绘制图如下：  

![](/images/sklearn/figure_3_3.png)

可以看出随着gamma值的增大，测试集的误差在增大，出现了过拟合的现象。  