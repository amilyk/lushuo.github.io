---
layout: post
title: "sklearn学习笔记（2）"
date: 2017-01-03 
description: "sklearn学习笔记"
tag: Scikit-learn

---

<h2> 交叉验证</h2>  
<h3>交叉验证目的</h3>  
通过交叉验证可以得到稳定可靠的模型。  
<h3>交叉验证方法</h3>  
**K-fold cross-validation：**K折交叉验证，也就是将数据集分成K份，将其中的K-1个数据集作为训练集，剩余一个作为测试集。测试进行K次以达到每一份都能作为测试集。常用的K的数据是10，也成10折交叉验证。通常K折交叉验证需要进行多次，也就是保证每次划分的K份就不会一样，这样能够充分利用数据集的数据。**优点**就是可以有效的避免过学习和欠学习的状态发生，以至于最终的结果具有说服性。**缺点**就是在K值的选择，需要不断尝试。  
**Holdout验证：**将原始数据分成两份，一份作为训练集，一份作为测试集。通常测试集的数据不超过三分之一。严格意义上将这种验证不属于交叉验证，因为数据并没有进行交叉使用。相较于K折交叉验证，这种验证可以称为double-fold cross-validation(2-CV)。**优点**是处理简单。**缺点**是严格意义来说Hold-Out Method并不能算是CV,因为这种方法没有达到交叉的思想,由于是随机的将原始数据分组,所以最后验证集分类准确率的高低与原始数据的分组有很大的关系,所以这种方法得到的结果其实并不具有说服性.(主要原因是 训练集样本数太少，通常不足以代表母体样本的分布，导致 test 阶段辨识率容易出现明显落差。此外，2-CV 中一分为二的分子集方法的变异度大，往往无法达到「实验过程必须可以被复制」的要求。)    
**留一验证：**留一验证（LOOCV）意指只使用原本样本中的一项来当做验证资料， 而剩余的则留下来当做训练资料。 这个步骤一直持续到每个样本都被当做一次验证资料。 事实上，这等同于 K-fold 交叉验证是一样的，其中K为原本样本个数。 在某些情况下是存在有效率的演算法，如使用kernel regression 和Tikhonov regularization。**优点**是每一个数据都能够充分利用。**缺点**是对于大的数据集带来的时空消耗太高，也容易导致过学习的情况。    
<h3>sklearn中交叉验证</h3>   
在sklearn中有专门的函数处理数据集，来自有sklearn模块中的cross_validation。  
以sklearn中提供的数据集iris为例，简单介绍该模块的使用。  

```python
from sklearn.datasets import load_iris
from sklearn.cross_validation import train_test_split
from sklearn.neighbors import KNeighborsClassifier
```

加载iris数据  

```python
iris=load_iris()
X=iris.data
y=iris.target
```

到了使用cross_validation模块的利器的时候了，train_test_split函数登场！！  

```python
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=4)
```

该函数很强大哦，将原来的数据进行打乱，按照test_size将数据分成训练集和测试集，并且random_state标注随机数的种子，一旦确定为某个值后，再次调用该函数划分仍然一样。  
但是这远远不够，因为这只是将数据分成了两份，也算是**Holdout验证方法**。但是如果针对**K折交叉验证**，这种就不可行了，那么就需要引入cross_validation模块的另外一个利器cross_val_score！  

```python
from sklearn.cross_validation import cross_val_score
knn=KNeighborsClassifier(n_neighbors=5)
scores=cross_val_score(knn,X,y,cv=5,scoring='accuracy')
```

这种方式相当于K折交叉验证，其中cv表示K折，scoring表示采用何种方式计算分数，这里采用准确度(accuracy)最高的方式。**scoring参数**：accuracy表示准确度一般用在分类，mean_squared_error用在回归问题表示误差（该误差是负数，一般操作起来需要在cross_val_score前面加上负号）。  

```python
loss = -cross_val_score(knn, X, y, cv=10, scoring='mean_squared_error')
```

scores会返回五个数值,如下：  

```python
array([ 0.96666667,  1.        ,  0.93333333,  0.96666667,  1.        ])
```

同时也可以通过这种当时测试**n_neighbors**（kNN中的K值）在(1,31)取值哪一个最好，具体代码如下：  

```python
from sklearn.cross_validation import cross_val_score
import matplotlib.pyplot as plt
k_range=range(1,31)
k_scores=[]
for k in k_range:
    knn = KNeighborsClassifier(k)
    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')
    k_scores.append(scores.mean())
plt.plot(k_range,k_scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Cross-Validated Accuracy')
```

交叉验证为10折，展示结果如下图：  

![](/images/sklearn/figure_1_1.png)



从图中可以清晰的看出，在n_neighbors=13的时候，精确值达到了最高，又因为防止过拟合的原因，不应该将n_neighbor的取值过大，所以n_neighbor的取值需要根据情况而定。  

参考博客：  
[机器学习-CrossValidation交叉验证Python实现](http://blog.csdn.net/dream_angel_z/article/details/47110077)  

